{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A framework for fast feature extraction\n",
    "\n",
    "https://www.kaggle.com/c/LANL-Earthquake-Prediction/discussion/80250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class FeatureGenerator(object):\n",
    "    def __init__(self, dtype, n_jobs=1, chunk_size=None):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.dtype = dtype\n",
    "        self.filename = None\n",
    "        self.n_jobs = n_jobs\n",
    "        self.test_files = []\n",
    "        if self.dtype == 'train':\n",
    "            self.filename = '../input/train.csv'\n",
    "            self.total_data = int(629145481 / self.chunk_size)\n",
    "        else:\n",
    "            submission = pd.read_csv('../input/sample_submission.csv')\n",
    "            for seg_id in submission.seg_id.values:\n",
    "                self.test_files.append((seg_id, '../input/test/' + seg_id + '.csv'))\n",
    "            self.total_data = int(len(submission))\n",
    "\n",
    "    def read_chunks(self):\n",
    "        if self.dtype == 'train':\n",
    "            iter_df = pd.read_csv(self.filename, iterator=True, chunksize=self.chunk_size,\n",
    "                                  dtype={'acoustic_data': np.float64, 'time_to_failure': np.float64})\n",
    "            for counter, df in enumerate(iter_df):\n",
    "                x = df.acoustic_data.values\n",
    "                y = df.time_to_failure.values[-1]\n",
    "                seg_id = 'train_' + str(counter)\n",
    "                yield seg_id, x, y\n",
    "        else:\n",
    "            for seg_id, f in self.test_files:\n",
    "                df = pd.read_csv(f, dtype={'acoustic_data': np.float64})\n",
    "                x = df.acoustic_data.values\n",
    "                yield seg_id, x, -999\n",
    "\n",
    "    def features(self, x, y, seg_id):\n",
    "        feature_dict = dict()\n",
    "        feature_dict['target'] = y\n",
    "        feature_dict['seg_id'] = seg_id\n",
    "\n",
    "        # create features here\n",
    "        # for example:\n",
    "        # feature_dict['mean'] = np.mean(x)\n",
    "\n",
    "        return feature_dict\n",
    "\n",
    "    def generate(self):\n",
    "        feature_list = []\n",
    "        res = Parallel(n_jobs=self.n_jobs,\n",
    "                       backend='threading')(delayed(self.features)(x, y, s)\n",
    "                                            for s, x, y in tqdm(self.read_chunks(), total=self.total_data))\n",
    "        for r in res:\n",
    "            feature_list.append(r)\n",
    "        return pd.DataFrame(feature_list)\n",
    "\n",
    "\n",
    "training_fg = FeatureGenerator(dtype='train', n_jobs=4, chunk_size=150000)\n",
    "training_data = training_fg.generate()\n",
    "\n",
    "test_fg = FeatureGenerator(dtype='test', n_jobs=4, chunk_size=None)\n",
    "test_data = test_fg.generate()\n",
    "\n",
    "training_data.to_csv(\"../input/train_features.csv\", index=False)\n",
    "test_data.to_csv(\"../input/test_features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
