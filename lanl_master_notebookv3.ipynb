{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master jupyter notebook for LANL - SlimBros Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly predicting earthquakes is very important for preventing deaths and damage to infrastructure. In this competition we try to predict time left to the next laboratory earthquake based on seismic signal data. Training data represents one huge signal, but in test data we have many separate chunks, for each of which we need to predict time to failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "Let's import everything we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import eli5\n",
    "import csv\n",
    "import dill\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "import feather\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm_notebook\n",
    "from altair.vega import v3\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import svm, neighbors, linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GridSearchCV, cross_val_score, ParameterGrid, train_test_split\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, SelectPercentile, SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "from utils import generate_segment_start_ids, compare_methods\n",
    "from features import gpi, create_all_features_extended\n",
    "from features import gpi_new, gpii_new, gpiii_new\n",
    "from features import gpi_tiny, gpii_tiny\n",
    "\n",
    "#Configure the environment\n",
    "%matplotlib inline\n",
    "pd.options.display.precision = 15\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "GLOBAL_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "requirejs.config({\n",
       "    baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
       "    paths: {\"vega\": \"https://cdn.jsdelivr.net/npm/vega@v3.3.1?noext\", \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\", \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@v3.2.1?noext\", \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@3?noext\"}\n",
       "});\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing altair. I use code from this great kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\n",
    "vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v3.SCHEMA_VERSION\n",
    "vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n",
    "vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n",
    "vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n",
    "noext = \"?noext\"\n",
    "\n",
    "paths = {\n",
    "    'vega': vega_url + noext,\n",
    "    'vega-lib': vega_lib_url + noext,\n",
    "    'vega-lite': vega_lite_url + noext,\n",
    "    'vega-embed': vega_embed_url + noext\n",
    "}\n",
    "\n",
    "workaround = \"\"\"\n",
    "requirejs.config({{\n",
    "    baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
    "    paths: {}\n",
    "}});\n",
    "\"\"\"\n",
    "\n",
    "#------------------------------------------------ Defs for future rendering\n",
    "def add_autoincrement(render_func):\n",
    "    # Keep track of unique <div/> IDs\n",
    "    cache = {}\n",
    "    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n",
    "        if autoincrement:\n",
    "            if id in cache:\n",
    "                counter = 1 + cache[id]\n",
    "                cache[id] = counter\n",
    "            else:\n",
    "                cache[id] = 0\n",
    "            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n",
    "        else:\n",
    "            if id not in cache:\n",
    "                cache[id] = 0\n",
    "            actual_id = id\n",
    "        return render_func(chart, id=actual_id)\n",
    "    # Cache will stay outside and \n",
    "    return wrapped\n",
    "            \n",
    "@add_autoincrement\n",
    "def render(chart, id=\"vega-chart\"):\n",
    "    chart_str = \"\"\"\n",
    "    <div id=\"{id}\"></div><script>\n",
    "    require([\"vega-embed\"], function(vg_embed) {{\n",
    "        const spec = {chart};     \n",
    "        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n",
    "        console.log(\"anything?\");\n",
    "    }});\n",
    "    console.log(\"really...anything?\");\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    return HTML(\n",
    "        chart_str.format(\n",
    "            id=id,\n",
    "            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n",
    "        )\n",
    "    )\n",
    "\n",
    "HTML(\"\".join((\n",
    "    \"<script>\",\n",
    "    workaround.format(json.dumps(paths)),\n",
    "    \"</script>\",\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load/compute the necessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_features = False \n",
    "# The computed features are saved in an hdf file along with the time_to_failure to \n",
    "# save the time spend reading the training data and the feature computation\n",
    "#train_data_format = 'csv'\n",
    "train_data_format = 'feather'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(file_format):\n",
    "    \"\"\"Loads the training dataset.\"\"\"\n",
    "    print(f'Loading data from {file_format} file:', end=\"\")\n",
    "    if file_format.lower() == 'feather':\n",
    "        train_df = feather.read_dataframe('../input/train.feather')\n",
    "    else:\n",
    "        train_df = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16,\n",
    "                                                            'time_to_failure': np.float32})\n",
    "        feather.write_dataframe(train_df, '../input/train.feather')\n",
    "    print(\"Done\")\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from feather file:Done\n"
     ]
    }
   ],
   "source": [
    "train = load_train_data(train_data_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 quakes on the training set.\n"
     ]
    }
   ],
   "source": [
    "time_to_failure_delta = np.diff(train['time_to_failure'])\n",
    "init_times = np.where(time_to_failure_delta > 5)[0].tolist()\n",
    "print(f'There are {len(init_times)} quakes on the training set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "- Usual aggregations: mean, std, min and max;\n",
    "- Average difference between the consequitive values in absolute and percent values;\n",
    "- Absolute min and max vallues;\n",
    "- Aforementioned aggregations for first and last 10000 and 50000 values - I think these data should be useful;\n",
    "- Max value to min value and their differencem also count of values bigger that 500 (arbitrary threshold);\n",
    "- Quantile features from this kernel: https://www.kaggle.com/andrekos/basic-feature-benchmark-with-quantiles\n",
    "- Trend features from this kernel: https://www.kaggle.com/jsaguiar/baseline-with-abs-and-trend-features\n",
    "- Rolling features from this kernel: https://www.kaggle.com/wimwim/rolling-quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_version = ''\n",
    "#features_version = 'v2'\n",
    "features_version = 'v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_files_present = (os.path.isfile(f'../tmp_results/X{features_version}_tr.hdf') and \n",
    "                       os.path.isfile(f'../tmp_results/X{features_version}_test.hdf') and \n",
    "                       os.path.isfile(f'../tmp_results/y{features_version}_tr.hdf') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files containing the features (v3) already exist.\n"
     ]
    }
   ],
   "source": [
    "if saved_files_present:\n",
    "    print(f'The files containing the features ({features_version}) already exist.')\n",
    "else:\n",
    "    print(f'The files containing the features ({features_version}) do not exist')\n",
    "    print(f'In the following step, the features will be computed. This may take several hours.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading hdf files (v3): Done\n"
     ]
    }
   ],
   "source": [
    "if (not compute_features) and saved_files_present:\n",
    "    print(f'Reading hdf files ({features_version}): ', end=\"\")\n",
    "    X_tr = pd.read_hdf(f'../tmp_results/X{features_version}_tr.hdf', 'data')\n",
    "    X_test = pd.read_hdf(f'../tmp_results/X{features_version}_test.hdf', 'data')\n",
    "    y_tr = pd.read_hdf(f'../tmp_results/y{features_version}_tr.hdf', 'data')  \n",
    "    print(\"Done\")\n",
    "else:\n",
    "    fs = 4000000 #Sampling frequency of the raw signal\n",
    "\n",
    "    #Compute features for the training data\n",
    "    segment_size = 150000\n",
    "    segment_start_ids = generate_segment_start_ids('uniform_no_jump', segment_size, train)\n",
    "    X_tr = pd.DataFrame(index=range(len(segment_start_ids)), dtype=np.float64)\n",
    "    y_tr = pd.DataFrame(index=range(len(segment_start_ids)), dtype=np.float64, columns=['time_to_failure'])\n",
    "    for idx in tqdm_notebook(range(len(segment_start_ids))):        \n",
    "        seg_id = segment_start_ids[idx]\n",
    "        seg = train.iloc[seg_id:seg_id + segment_size]\n",
    "        create_all_features_extended(idx, seg, X_tr, fs)\n",
    "        y_tr.loc[idx, 'time_to_failure'] = seg['time_to_failure'].values[-1]\n",
    "    # Sanity check\n",
    "    means_dict = {}\n",
    "    for col in X_tr.columns:\n",
    "        if X_tr[col].isnull().any():\n",
    "            print(col)\n",
    "            mean_value = X_tr.loc[X_tr[col] != -np.inf, col].mean()\n",
    "            X_tr.loc[X_tr[col] == -np.inf, col] = mean_value\n",
    "            X_tr[col] = X_tr[col].fillna(mean_value)\n",
    "            means_dict[col] = mean_value\n",
    "\n",
    "    #Compute features for the test data\n",
    "    submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')\n",
    "    X_test = pd.DataFrame(columns=X_tr.columns, dtype=np.float64, index=submission.index)\n",
    "    for i, seg_id in enumerate(tqdm_notebook(X_test.index)):\n",
    "        seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "        create_all_features_extended(seg_id, seg, X_test, fs)\n",
    "\n",
    "    # Sanity check\n",
    "    for col in X_test.columns:\n",
    "        if X_test[col].isnull().any():\n",
    "            X_test.loc[X_test[col] == -np.inf, col] = means_dict[col]\n",
    "            X_test[col] = X_test[col].fillna(means_dict[col])\n",
    "            \n",
    "    X_tr.to_hdf(f'../tmp_results/X{features_version}_tr.hdf', 'data')\n",
    "    X_test.to_hdf(f'../tmp_results/X{features_version}_test.hdf', 'data')\n",
    "    y_tr.to_hdf(f'../tmp_results/y{features_version}_tr.hdf', 'data')\n",
    "    \n",
    "    del segment_start_ids\n",
    "    del means_dict\n",
    "    del submission\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.concat([X_tr, X_test])\n",
    "scaler = StandardScaler()\n",
    "alldata = pd.DataFrame(scaler.fit_transform(alldata), columns=alldata.columns)\n",
    "X_train_scaled = alldata[:X_tr.shape[0]]\n",
    "X_test_scaled = alldata[X_tr.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, folds, params=None, model_type='lgb',\n",
    "                model=None, show_scatter=False, force_positive=False,\n",
    "                compute_feature_importance=True):\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    n_fold = folds.get_n_splits()\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "           \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = 50000, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                      eval_metric='mae',\n",
    "                      verbose=0,\n",
    "                      early_stopping_rounds=100)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            if force_positive:\n",
    "                y_pred_valid = y_pred_valid.clip(min=0)\n",
    "          \n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data,\n",
    "                              num_boost_round=20000,\n",
    "                              evals=watchlist,\n",
    "                              early_stopping_rounds=100,\n",
    "                              verbose_eval=0,\n",
    "                              params=params)\n",
    "\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns),\n",
    "                                         ntree_limit=model.best_ntree_limit)\n",
    "            if force_positive:\n",
    "                y_pred_valid = y_pred_valid.clip(min=0)\n",
    "          \n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns),\n",
    "                                   ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'gpi':\n",
    "            y_pred_valid = gpi(X_valid, activation=params['activation']).values\n",
    "            y_pred = gpi(X_test, activation=params['activation']).values\n",
    "            if force_positive:\n",
    "                y_pred_valid = y_pred_valid.clip(min=0)\n",
    "\n",
    "        if model_type == 'gpi_new':\n",
    "            y_pred_valid = gpi_new(X_valid, activation=params['activation']).values\n",
    "            y_pred = gpi_new(X_test, activation=params['activation']).values\n",
    "            if force_positive:\n",
    "                y_pred_valid = y_pred_valid.clip(min=0)\n",
    "            \n",
    "        if model_type == 'gpii_new':\n",
    "            y_pred_valid = gpii_new(X_valid, activation=params['activation']).values\n",
    "            y_pred = gpii_new(X_test, activation=params['activation']).values\n",
    "            if force_positive:\n",
    "                y_pred_valid = y_pred_valid.clip(min=0)\n",
    "                \n",
    "        if model_type == 'gpiii_new':\n",
    "            y_pred_valid = gpiii_new(X_valid, activation=params['activation']).values\n",
    "            y_pred = gpiii_new(X_test, activation=params['activation']).values\n",
    "            if force_positive:\n",
    "                y_pred_valid = y_pred_valid.clip(min=0)\n",
    "                \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(mean_absolute_error(y_valid, y_pred_valid))\n",
    "        \n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and compute_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance['feature'] = X.columns\n",
    "            fold_importance['importance'] = model.feature_importances_\n",
    "            fold_importance['fold'] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    if force_positive:\n",
    "        prediction = prediction.clip(min=0)    \n",
    "    \n",
    "    if show_scatter:\n",
    "        fig, axis = plt.subplots(1, 2, figsize=(12,5))\n",
    "        ax1, ax2 = axis\n",
    "        ax1.set_xlabel('actual')\n",
    "        ax1.set_ylabel('predicted')\n",
    "        ax2.set_xlabel('train index')\n",
    "        ax2.set_ylabel('time to failure')\n",
    "        \n",
    "        ax1.scatter(y, oof, color='brown')\n",
    "        ax1.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)], color='blue')\n",
    "\n",
    "        ax2.plot(y, color='blue', label='y_train')\n",
    "        ax2.plot(oof, color='orange')\n",
    "    \n",
    "    print(f'CV mean score: {np.mean(scores):.4f}, std: {np.std(scores):.4f}.')\n",
    "    \n",
    "    if model_type == 'lgb' and compute_feature_importance:\n",
    "        feature_importance['importance'] /= n_fold\n",
    "        return oof, prediction, scores, feature_importance\n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "folds_models = KFold(n_splits=n_fold, shuffle=True, random_state=GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few different models and submit the one with the best validation score. The predicted values in the following plots are using a out-of-fold scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 18 21:46:27 2019\n",
      "Fold 1 started at Sat May 18 21:46:59 2019\n",
      "Fold 2 started at Sat May 18 21:47:40 2019\n",
      "Fold 3 started at Sat May 18 21:48:14 2019\n",
      "Fold 4 started at Sat May 18 21:48:55 2019\n",
      "CV mean score: 2.0094, std: 0.0804.\n"
     ]
    }
   ],
   "source": [
    "#TODO: optimize params\n",
    "params_lgb = {\n",
    "    'objective': 'huber',\n",
    "    'boosting': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 12,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.005,\n",
    "    'bagging_freq': 4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_seed': 11,\n",
    "    'random_seed': GLOBAL_SEED,\n",
    "    'metric': 'mae',\n",
    "    'reg_alpha': 0.47777777777777775,\n",
    "    'reg_lambda': 0.47777777777777775\n",
    "}\n",
    "oof_lgb, prediction_lgb, scores_lgb, feature_importance_lgb = train_model(X=X_train_scaled,\n",
    "                                                                          X_test=X_test_scaled,\n",
    "                                                                          y=y_tr,\n",
    "                                                                          folds=folds_models,\n",
    "                                                                          params=params_lgb,\n",
    "                                                                          model_type='lgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 18 21:49:40 2019\n",
      "Fold 1 started at Sat May 18 21:49:47 2019\n",
      "Fold 2 started at Sat May 18 21:49:57 2019\n",
      "Fold 3 started at Sat May 18 21:50:07 2019\n",
      "Fold 4 started at Sat May 18 21:50:16 2019\n",
      "CV mean score: 2.0066, std: 0.0778.\n"
     ]
    }
   ],
   "source": [
    "#TODO: optimize params\n",
    "params_xgb = {\n",
    "    'eta': 0.01,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.5,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'silent': True,\n",
    "    'nthread': 32\n",
    "}\n",
    "oof_xgb, prediction_xgb, scores_xgb = train_model(X=X_train_scaled,\n",
    "                                                  X_test=X_test_scaled,\n",
    "                                                  y=y_tr,\n",
    "                                                  folds=folds_models,\n",
    "                                                  params=params_xgb,\n",
    "                                                  model_type='xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Program Models (borrowed from Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 18 21:50:26 2019\n",
      "Fold 1 started at Sat May 18 21:50:27 2019\n",
      "Fold 2 started at Sat May 18 21:50:28 2019\n",
      "Fold 3 started at Sat May 18 21:50:29 2019\n",
      "Fold 4 started at Sat May 18 21:50:30 2019\n",
      "CV mean score: 1.9140, std: 0.0853.\n",
      "Fold 0 started at Sat May 18 21:50:31 2019\n",
      "Fold 1 started at Sat May 18 21:50:31 2019\n",
      "Fold 2 started at Sat May 18 21:50:32 2019\n",
      "Fold 3 started at Sat May 18 21:50:33 2019\n",
      "Fold 4 started at Sat May 18 21:50:33 2019\n",
      "CV mean score: 1.9543, std: 0.0955.\n",
      "Fold 0 started at Sat May 18 21:50:34 2019\n",
      "Fold 1 started at Sat May 18 21:50:35 2019\n",
      "Fold 2 started at Sat May 18 21:50:35 2019\n",
      "Fold 3 started at Sat May 18 21:50:36 2019\n",
      "Fold 4 started at Sat May 18 21:50:37 2019\n",
      "CV mean score: 1.9698, std: 0.0927.\n",
      "Fold 0 started at Sat May 18 21:50:37 2019\n",
      "Fold 1 started at Sat May 18 21:50:38 2019\n",
      "Fold 2 started at Sat May 18 21:50:39 2019\n",
      "Fold 3 started at Sat May 18 21:50:39 2019\n",
      "Fold 4 started at Sat May 18 21:50:40 2019\n",
      "CV mean score: 1.9563, std: 0.0912.\n"
     ]
    }
   ],
   "source": [
    "params_gpi = {\n",
    "    'activation':'atan'\n",
    "}\n",
    "oof_gpi, prediction_gpi, scores_gpi = train_model(X=X_train_scaled,\n",
    "                                                  X_test=X_test_scaled,\n",
    "                                                  y=y_tr,\n",
    "                                                  folds=folds_models,\n",
    "                                                  params=params_gpi,\n",
    "                                                  model_type='gpi')\n",
    "\n",
    "params_gpi_new = {\n",
    "    'activation':'atan'\n",
    "}\n",
    "oof_gpi_new, prediction_gpi_new, scores_gpi_new = train_model(X=X_train_scaled,\n",
    "                                                              X_test=X_test_scaled,\n",
    "                                                              y=y_tr,\n",
    "                                                              folds=folds_models,\n",
    "                                                              params=params_gpi_new,\n",
    "                                                              model_type='gpi_new')\n",
    "\n",
    "params_gpii_new = {\n",
    "    'activation':'atan'\n",
    "}\n",
    "oof_gpii_new, prediction_gpii_new, scores_gpii_new = train_model(X=X_train_scaled,\n",
    "                                                                 X_test=X_test_scaled,\n",
    "                                                                 y=y_tr,\n",
    "                                                                 folds=folds_models,\n",
    "                                                                 params=params_gpii_new,\n",
    "                                                                 model_type='gpii_new')\n",
    "\n",
    "params_gpiii_new = {\n",
    "    'activation':'atan'\n",
    "}\n",
    "oof_gpiii_new, prediction_gpiii_new, scores_gpiii_new = train_model(X=X_train_scaled,\n",
    "                                                                    X_test=X_test_scaled,\n",
    "                                                                    y=y_tr,\n",
    "                                                                    folds=folds_models,\n",
    "                                                                    params=params_gpiii_new,\n",
    "                                                                    model_type='gpiii_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8));\n",
    "scores_df = pd.DataFrame()\n",
    "try:\n",
    "    scores_df['LGBMRegressor'] = scores_lgb\n",
    "except NameError:\n",
    "    print('LGBMRegressor not computed')\n",
    "try:\n",
    "    scores_df['XGBRegressor'] = scores_xgb\n",
    "except NameError:\n",
    "    print('XGBRegressor not computed')\n",
    "try:\n",
    "    scores_df['GPI'] = scores_gpi\n",
    "except NameError:\n",
    "    print('GPI not computed')\n",
    "try:\n",
    "    scores_df['GPI_new'] = scores_gpi_new\n",
    "except NameError:\n",
    "    print('GPI_new not computed')\n",
    "try:\n",
    "    scores_df['GPII_new'] = scores_gpii_new\n",
    "except NameError:\n",
    "    print('GPII_new not computed')    \n",
    "try:\n",
    "    scores_df['GPIII_new'] = scores_gpiii_new\n",
    "except NameError:\n",
    "    print('GPIII_new not computed')     \n",
    "    \n",
    "ax = sns.boxplot(data=scores_df.reindex(scores_df.mean().sort_values().index, axis=1));\n",
    "ax = sns.swarmplot(data=scores_df.reindex(scores_df.mean().sort_values().index, axis=1), color=\".25\")\n",
    "\n",
    "plt.xticks(rotation=45);\n",
    "plt.xlabel('Method');\n",
    "plt.ylabel('CV Score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dill.dump_session('notebook_env.db')\n",
    "#dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping highly correlated features\n",
    "Due to the huge number of features there are certainly some highly correlated features, let's try droping them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_uncorr = X_train_scaled.copy()\n",
    "X_test_scaled_uncorr = X_test_scaled.copy()\n",
    "# https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/\n",
    "corr_matrix = X_train_scaled_uncorr.corr().abs()\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# Find index of feature columns with correlation greater than 0.99\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.99)]\n",
    "X_train_scaled_uncorr = X_train_scaled_uncorr.drop(to_drop, axis=1)\n",
    "X_test_scaled_uncorr = X_test_scaled_uncorr.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 18 21:51:05 2019\n",
      "Fold 1 started at Sat May 18 21:51:21 2019\n",
      "Fold 2 started at Sat May 18 21:51:39 2019\n",
      "Fold 3 started at Sat May 18 21:51:53 2019\n",
      "Fold 4 started at Sat May 18 21:52:10 2019\n",
      "CV mean score: 2.0185, std: 0.0788.\n"
     ]
    }
   ],
   "source": [
    "#TODO: Optimize\n",
    "params_lgb_uncorr = {\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_freq': 4,\n",
    "    'bagging_seed': 11,\n",
    "    'boosting': 'gbdt',\n",
    "    'reg_alpha': 0.47777777777777775,\n",
    "    'reg_lambda': 0.47777777777777775,\n",
    "    'learning_rate': 0.005,\n",
    "    'max_depth': 8,\n",
    "    'metric': 'mae',\n",
    "    'min_data_in_leaf': 40,\n",
    "    'num_leaves': 12,    \n",
    "    'objective': 'huber',\n",
    "    'verbosity': -1,\n",
    "    'random_seed': GLOBAL_SEED\n",
    "}\n",
    "oof_lgb_uncorr, prediction_lgb_uncorr, scores_lgb_uncorr = train_model(\n",
    "    X=X_train_scaled_uncorr,\n",
    "    X_test=X_test_scaled_uncorr,\n",
    "    y=y_tr,\n",
    "    folds=folds_models,\n",
    "    params=params_lgb_uncorr,\n",
    "    model_type='lgb',\n",
    "    compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELI5 and permutation importance\n",
    "ELI5 is a package with provides explanations for ML models. It can do this not only for linear models, but also for tree based like Random Forest or lightgbm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute_eli5 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\n",
    "    'objective': 'huber',\n",
    "    'boosting': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 12,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.005,\n",
    "    'bagging_freq': 4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_seed': 11,\n",
    "    'random_seed': GLOBAL_SEED,\n",
    "    'metric': 'mae',\n",
    "    'reg_alpha': 0.47777777777777775,\n",
    "    'reg_lambda': 0.47777777777777775\n",
    "}\n",
    "if recompute_eli5:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_scaled, y_tr, test_size=0.2)\n",
    "    model = lgb.LGBMRegressor(**params_lgb, n_estimators = 50000, n_jobs = -1, verbose=-1)\n",
    "    model.fit(X_train,\n",
    "              y_train, \n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              eval_metric='mae',\n",
    "              verbose=10000,\n",
    "              early_stopping_rounds=200)\n",
    "    perm = eli5.sklearn.PermutationImportance(model, random_state=1).fit(X_train, y_train)\n",
    "    #eli5.show_weights(perm, top=200, feature_names=X_train_scaled.columns.values.tolist())\n",
    "    top_num_features = 150\n",
    "    top_features = [i for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i][:top_num_features]\n",
    "\n",
    "    top_features_df = pd.DataFrame(data=top_features)\n",
    "    top_features_df.columns = ['top_features']\n",
    "    top_features_df.to_csv(f'../tmp_results/top_features_eli5.csv', index=False)\n",
    "else:\n",
    "    top_features = pd.read_csv(f'../tmp_results/top_features_eli5.csv')['top_features'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat May 18 21:52:28 2019\n",
      "Fold 1 started at Sat May 18 21:52:32 2019\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e871468daaa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_lgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     compute_feature_importance=False)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-e4eeae2d290a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X, X_test, y, folds, params, model_type, model, show_scatter, force_positive, compute_feature_importance)\u001b[0m\n\u001b[1;32m     24\u001b[0m                       \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                       early_stopping_rounds=100)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0my_pred_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/user/toolse64/ubuntu/18.04/usr/local/tools/anaconda_2018.12/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    640\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/user/toolse64/ubuntu/18.04/usr/local/tools/anaconda_2018.12/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    500\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/user/toolse64/ubuntu/18.04/usr/local/tools/anaconda_2018.12/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    211\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/user/toolse64/ubuntu/18.04/usr/local/tools/anaconda_2018.12/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1753\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1754\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "oof_lgb_eli5_top, prediction_lgb_eli5_top, scores_lgb_eli5_top = train_model(\n",
    "    X=X_train_scaled[top_features],\n",
    "    X_test=X_test_scaled[top_features],\n",
    "    y=y_tr,\n",
    "    folds=folds_models,\n",
    "    params=params_lgb,\n",
    "    model_type='lgb',\n",
    "    compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute_eli5_uncorr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb_uncorr = {\n",
    "    'objective': 'huber',\n",
    "    'boosting': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 12,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.005,\n",
    "    'bagging_freq': 4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_seed': 11,\n",
    "    'random_seed': GLOBAL_SEED,\n",
    "    'metric': 'mae',\n",
    "    'reg_alpha': 0.47777777777777775,\n",
    "    'reg_lambda': 0.47777777777777775\n",
    "}\n",
    "if recompute_eli5_uncorr:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_scaled_uncorr, y_tr, test_size=0.2)\n",
    "    model = lgb.LGBMRegressor(**params_lgb_uncorr, n_estimators = 50000, n_jobs = -1, verbose=-1)\n",
    "    model.fit(X_train,\n",
    "              y_train, \n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              eval_metric='mae',\n",
    "              verbose=10000,\n",
    "              early_stopping_rounds=200)\n",
    "    perm = eli5.sklearn.PermutationImportance(model, random_state=1).fit(X_train, y_train)\n",
    "    #eli5.show_weights(perm, top=200, feature_names=X_train_scaled.columns.values.tolist())\n",
    "    top_num_features = 150\n",
    "    top_features = [i for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i][:top_num_features]\n",
    "\n",
    "    top_features_df = pd.DataFrame(data=top_features)\n",
    "    top_features_df.columns = ['top_features']\n",
    "    top_features_df.to_csv(f'../tmp_results/top_features_eli5_uncorr.csv', index=False)\n",
    "else:\n",
    "    top_features = pd.read_csv(f'../tmp_results/top_features_eli5_uncorr.csv')['top_features'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lgb_eli5_uncorr_top, prediction_lgb_eli5_uncorr_top, scores_lgb_eli5_uncorr_top = train_model(\n",
    "    X=X_train_scaled_uncorr[top_features],\n",
    "    X_test=X_test_scaled_uncorr[top_features],\n",
    "    y=y_tr,\n",
    "    folds=folds_models,\n",
    "    params=params_lgb_uncorr,\n",
    "    model_type='lgb',\n",
    "    compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE (Feature ranking with recursive feature elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute_rfe_analysis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recompute_rfe_analysis:\n",
    "    scores_dict = {'rfe_score': [], 'n_features': []}\n",
    "    total_num_features = X_train_scaled_uncorr.shape[1]\n",
    "    rfe_feat = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 20, 30, 40, 50,\n",
    "                110, 150, 210, 250, 310, 350, 410, 510,\n",
    "                610, 710, 810, 850, 910, 950, 1010, 1113]\n",
    "    for i in tqdm_notebook(rfe_feat):\n",
    "        model = lgb.LGBMRegressor(**params_lgb_uncorr, n_estimators = 50000, n_jobs = -1, verbose=-1)\n",
    "        s1 = RFE(model, i, step=100)\n",
    "        #s1 = SelectPercentile(f_classif, percentile=i)\n",
    "        #s2 = SelectPercentile(mutual_info_classif, percentile=i)\n",
    "        #s1 = SelectKBest(f_classif, k=i)\n",
    "        X_train1 = s1.fit_transform(X_train_scaled_uncorr, y_tr.values.astype(int))\n",
    "        X_test1 = s1.transform(X_test_scaled_uncorr)    \n",
    "        oof, prediction, scores = train_model(X=X_train1,\n",
    "                                              X_test=X_test1,\n",
    "                                              y=y_tr.values.reshape(-1, ),\n",
    "                                              params=params_lgb_uncorr,\n",
    "                                              folds=folds_models,\n",
    "                                              model_type='lgb',\n",
    "                                              compute_feature_importance=False)\n",
    "        scores_dict['rfe_score'].append(np.mean(scores))    \n",
    "        scores_dict['n_features'].append(X_train1.shape[1])\n",
    "        scores_df = pd.DataFrame(scores_dict)\n",
    "        scores_df.to_csv(f'../tmp_results/rfe_scores.csv', index=False)\n",
    "else:\n",
    "    scores_df = pd.read_csv(f'../tmp_results/rfe_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores_df = scores_df.melt(id_vars=['n_features'], value_vars=['rfe_score'], var_name='metric', value_name='mae')\n",
    "max_value = scores_df['mae'].max() * 1.01\n",
    "min_value = scores_df['mae'].min() * 0.99\n",
    "render(alt.Chart(scores_df).mark_line().encode(\n",
    "    y=alt.Y('mae:Q', scale=alt.Scale(domain=(min_value, max_value))),\n",
    "    x='n_features:Q',\n",
    "    color='metric:N',\n",
    "    tooltip=['metric:N', 'n:O', 'mae:Q']\n",
    ").properties(\n",
    "    title='Top N features by RFE vs CV'\n",
    ").interactive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb_rfe_uncorr_top = {\n",
    "    'objective': 'huber',\n",
    "    'boosting': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 12,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.005,\n",
    "    'bagging_freq': 4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_seed': 11,\n",
    "    'random_seed': GLOBAL_SEED,\n",
    "    'metric': 'mae',\n",
    "    'reg_alpha': 0.47777777777777775,\n",
    "    'reg_lambda': 0.47777777777777775\n",
    "}\n",
    "top_num_features = 150\n",
    "model = lgb.LGBMRegressor(**params_lgb_rfe_uncorr_top, n_estimators = 50000, n_jobs = -1, verbose=-1)\n",
    "s1 = RFE(model, top_num_features, step=100)\n",
    "X_train1 = s1.fit_transform(X_train_scaled_uncorr, y_tr.values.astype(int))\n",
    "X_test1 = s1.transform(X_test_scaled_uncorr)\n",
    "oof_lgb_rfe_uncorr_top, prediction_lgb_rfe_uncorr_top, scores_lgb_rfe_uncorr_top = train_model(\n",
    "    X=X_train1,\n",
    "    X_test=X_test1,\n",
    "    y=y_tr.values.reshape(-1, ),\n",
    "    params=params_lgb_rfe_uncorr_top,\n",
    "    folds=folds_models,\n",
    "    model_type='lgb',\n",
    "    compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a sligh modification on the objective function may yield important gains. The idea is that using sqrt(```time_to_failure```) and using MSE gives much better performance on MAE once squaring the predictions. \n",
    "https://www.kaggle.com/c/LANL-Earthquake-Prediction/discussion/92440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb_rfe_uncorr_top = {\n",
    "    'objective': 'huber',\n",
    "    'boosting': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 12,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.005,\n",
    "    'bagging_freq': 4,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'bagging_seed': 11,\n",
    "    'random_seed': GLOBAL_SEED,\n",
    "    'metric': 'mae',\n",
    "    'reg_alpha': 0.47777777777777775,\n",
    "    'reg_lambda': 0.47777777777777775\n",
    "}\n",
    "top_num_features = 150\n",
    "s1 = RFE(model, top_num_features, step=100)\n",
    "X_train1 = s1.fit_transform(X_train_scaled_uncorr, y_tr.values.astype(int))\n",
    "X_test1 = s1.transform(X_test_scaled_uncorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lgb_rfe_uncorr_top, prediction_lgb_rfe_uncorr_top, scores_lgb_rfe_uncorr_top = train_model(X=X_train1,\n",
    "    X_test=X_test1,\n",
    "    y=y_tr.values.reshape(-1, ),\n",
    "    params=params_lgb_rfe_uncorr_top,\n",
    "    folds=folds_models,\n",
    "    model_type='lgb_sq',\n",
    "    compute_feature_importance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model compatison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8));\n",
    "scores_df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    scores_df['LGB'] = scores_lgb\n",
    "except NameError:\n",
    "    print('LGB not computed')\n",
    "try:\n",
    "    scores_df['LGB_eli5_top'] = scores_lgb_eli5_top\n",
    "except NameError:\n",
    "    print('LGB_eli5_top not computed')\n",
    "try:\n",
    "    scores_df['LGB_uncorr'] = scores_lgb_uncorr\n",
    "except NameError:\n",
    "    print('LGB_uncorr not computed')\n",
    "try:\n",
    "    scores_df['LGB_eli5_uncorr_top'] = scores_lgb_eli5_uncorr_top\n",
    "except NameError:\n",
    "    print('LGB_eli5_uncorr_top not computed')\n",
    "try:\n",
    "    scores_df['LGB_rfe_uncorr_top'] = scores_lgb_rfe_uncorr_top\n",
    "except NameError:\n",
    "    print('LGB_rfe_uncorr_top not computed')    \n",
    "try:\n",
    "    scores_df['XGB'] = scores_xgb\n",
    "except NameError:\n",
    "    print('XGB not computed')\n",
    "try:\n",
    "    scores_df['GPI'] = scores_gpi\n",
    "except NameError:\n",
    "    print('GPI not computed')\n",
    "try:\n",
    "    scores_df['GPI_new'] = scores_gpi_new\n",
    "except NameError:\n",
    "    print('GPI_new not computed')\n",
    "try:\n",
    "    scores_df['GPII_new'] = scores_gpii_new\n",
    "except NameError:\n",
    "    print('GPII_new not computed')    \n",
    "try:\n",
    "    scores_df['GPIII_new'] = scores_gpiii_new\n",
    "except NameError:\n",
    "    print('GPIII_new not computed')\n",
    "    \n",
    "ax = sns.boxplot(data=scores_df.reindex(scores_df.mean().sort_values().index, axis=1));\n",
    "#ax.set(yscale=\"log\")\n",
    "\n",
    "plt.xticks(rotation=45);\n",
    "plt.xlabel('Method');\n",
    "plt.ylabel('Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_blend_gp = (prediction_gpi +\n",
    "                    prediction_gpi_new + \n",
    "                    prediction_gpii_new + \n",
    "                    prediction_gpiii_new) / 4\n",
    "oof_blend_gp = (oof_gpi +\n",
    "             oof_gpi_new + \n",
    "             oof_gpii_new + \n",
    "             oof_gpiii_new) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(dtype=np.float64)\n",
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')\n",
    "submission['time_to_failure'] = prediction_lgb_eli5_top\n",
    "submission.to_csv('../output/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env.db')\n",
    "#dill.load_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
