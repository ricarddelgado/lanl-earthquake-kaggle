{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature-based predictor\n",
    "This notebook is based on [Andrew Lukyanenko](https://www.kaggle.com/artgor)'s [kernel](https://www.kaggle.com/artgor/earthquakes-fe-more-features-and-samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General information\n",
    "Correctly predicting earthquakes is very important for preventing deaths and damage to infrastructure. In this competition we try to predict time left to the next laboratory earthquake based on seismic signal data. Training data represents one huge signal, but in test data we have many separate chunks, for each of which we need to predict time to failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "Let's import everything we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from catboost import CatBoostRegressor\n",
    "from scipy import stats\n",
    "from scipy.signal import hilbert, hann, convolve\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GridSearchCV\n",
    "from utils import freq_from_crossings, freq_from_fft\n",
    "from features import gpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.options.display.precision = 15\n",
    "warnings.filterwarnings('ignore')\n",
    "random.seed(1013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \"\"\"\n\u001b[1;32m    779\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})\n",
    "fs = 4000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2b7448ad5ccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train: rows:{train.shape[0]} cols:{train.shape[1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Train: rows:{train.shape[0]} cols:{train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_acoustic_data_small = train['acoustic_data'].values[::50]\n",
    "train_time_to_failure_small = train['time_to_failure'].values[::50]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "plt.title('Trends of acoustic_data and time_to_failure. 2% of data (sampled)')\n",
    "plt.plot(train_acoustic_data_small, color='b')\n",
    "ax1.set_ylabel('acoustic_data', color='b')\n",
    "plt.legend(['acoustic_data'])\n",
    "ax2 = ax1.twinx()\n",
    "plt.plot(train_time_to_failure_small, color='g')\n",
    "ax2.set_ylabel('time_to_failure', color='g')\n",
    "plt.legend(['time_to_failure'], loc=(0.875, 0.9))\n",
    "plt.grid(False)\n",
    "\n",
    "del train_acoustic_data_small\n",
    "del train_time_to_failure_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acoustic_data_small = train['acoustic_data'].values[:15000000]\n",
    "train_time_to_failure_small = train['time_to_failure'].values[:15000000]\n",
    "fig, ax1 = plt.subplots(figsize=(16, 8))\n",
    "plt.title('Trends of acoustic_data and time_to_failure. 2% of data (sampled)')\n",
    "plt.plot(train_acoustic_data_small, color='b')\n",
    "ax1.set_ylabel('acoustic_data', color='b')\n",
    "plt.legend(['acoustic_data'])\n",
    "ax2 = ax1.twinx()\n",
    "plt.plot(train_time_to_failure_small, color='g')\n",
    "ax2.set_ylabel('time_to_failure', color='g')\n",
    "plt.legend(['time_to_failure'], loc=(0.875, 0.9))\n",
    "plt.grid(False)\n",
    "\n",
    "del train_acoustic_data_small\n",
    "del train_time_to_failure_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that usually acoustic data shows huge fluctuations just before the failure and the nature of data is cyclical;\n",
    "- Another important point: visually failures can be predicted as cases when huge fluctuations in signal are followes by small signal values. This could be useful for predicting `time_to_failure` changes from 0 to high values;\n",
    "- I thought that comparing max values of signal in a segment to some threshold value (1000 or 2000) could be useful, but it didn't work;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.hist(train['time_to_failure'].values[::50], bins='auto', density=True)  # arguments are passed to np.histogram\n",
    "plt.title('Histogram of time_to_failure')\n",
    "plt.xlabel('time_to_failure')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The time to training is not uniforally distribured on the training set. Resampling could be interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "- Usual aggregations: mean, std, min and max;\n",
    "- Average difference between the consequitive values in absolute and percent values;\n",
    "- Absolute min and max vallues;\n",
    "- Aforementioned aggregations for first and last 10000 and 50000 values - I think these data should be useful;\n",
    "- Max value to min value and their differencem also count of values bigger that 500 (arbitrary threshold);\n",
    "- Quantile features from this kernel: https://www.kaggle.com/andrekos/basic-feature-benchmark-with-quantiles\n",
    "- Trend features from this kernel: https://www.kaggle.com/jsaguiar/baseline-with-abs-and-trend-features\n",
    "- Rolling features from this kernel: https://www.kaggle.com/wimwim/rolling-quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trend_feature(arr, abs_values=False):\n",
    "    idx = np.array(range(len(arr)))\n",
    "    if abs_values:\n",
    "        arr = np.abs(arr)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(idx.reshape(-1, 1), arr)\n",
    "    return lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_sta_lta(x, length_sta, length_lta, method='Andrew'):\n",
    "    if method=='Andrew':\n",
    "        sta = np.cumsum(x ** 2)\n",
    "        # Convert to float\n",
    "        sta = np.require(sta, dtype=np.float)\n",
    "        # Copy for LTA\n",
    "        lta = sta.copy()\n",
    "        # Compute the STA and the LTA\n",
    "        sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "        sta /= length_sta\n",
    "        lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "        lta /= length_lta\n",
    "        # Pad zeros\n",
    "        sta[:length_lta - 1] = 0\n",
    "        # Avoid division by zero by setting zero values to tiny float\n",
    "        dtiny = np.finfo(0.0).tiny\n",
    "        idx = lta < dtiny\n",
    "        lta[idx] = dtiny\n",
    "        ratio_andrew = sta / lta\n",
    "        \n",
    "    elif method == 'Ricard':\n",
    "        x_abs = np.abs(x)\n",
    "        # Convert to float\n",
    "        x_abs = np.require(x_abs, dtype=np.float)\n",
    "        # Compute the STA and the LTA\n",
    "        sta = np.cumsum(x_abs)\n",
    "        sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "        sta = sta[length_sta - 1:] / length_sta\n",
    "        sta = sta[:-(length_lta-length_sta)]\n",
    "        lta = x_abs.copy()\n",
    "        lta = np.cumsum(lta)\n",
    "        lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "        lta = lta[length_lta - 1:] / length_lta\n",
    "        ratio = sta / lta\n",
    "\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_change_rate(x):\n",
    "    change = (np.diff(x) / x[:-1]).values\n",
    "    change = change[np.nonzero(change)[0]]\n",
    "    change = change[~np.isnan(change)]\n",
    "    change = change[change != -np.inf]\n",
    "    change = change[change != np.inf]\n",
    "    return np.mean(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(seg_id, seg, X):\n",
    "    xc = pd.Series(seg['acoustic_data'].values)\n",
    "    zc = np.fft.fft(xc)\n",
    "    \n",
    "    # Generic stats\n",
    "    X.loc[seg_id, 'mean'] = xc.mean()\n",
    "    X.loc[seg_id, 'std'] = xc.std()\n",
    "    X.loc[seg_id, 'max'] = xc.max()\n",
    "    X.loc[seg_id, 'min'] = xc.min()\n",
    "    \n",
    "    #FFT transform values\n",
    "    realFFT = np.real(zc)\n",
    "    imagFFT = np.imag(zc)\n",
    "    X.loc[seg_id, 'Rmean'] = realFFT.mean()\n",
    "    X.loc[seg_id, 'Rstd'] = realFFT.std()\n",
    "    X.loc[seg_id, 'Rmax'] = realFFT.max()\n",
    "    X.loc[seg_id, 'Rmin'] = realFFT.min()\n",
    "    X.loc[seg_id, 'Imean'] = imagFFT.mean()\n",
    "    X.loc[seg_id, 'Istd'] = imagFFT.std()\n",
    "    X.loc[seg_id, 'Imax'] = imagFFT.max()\n",
    "    X.loc[seg_id, 'Imin'] = imagFFT.min()\n",
    "    X.loc[seg_id, 'Rmean_last_5000'] = realFFT[-5000:].mean()\n",
    "    X.loc[seg_id, 'Rstd__last_5000'] = realFFT[-5000:].std()\n",
    "    X.loc[seg_id, 'Rmax_last_5000'] = realFFT[-5000:].max()\n",
    "    X.loc[seg_id, 'Rmin_last_5000'] = realFFT[-5000:].min()\n",
    "    X.loc[seg_id, 'Rmean_last_15000'] = realFFT[-15000:].mean()\n",
    "    X.loc[seg_id, 'Rstd_last_15000'] = realFFT[-15000:].std()\n",
    "    X.loc[seg_id, 'Rmax_last_15000'] = realFFT[-15000:].max()\n",
    "    X.loc[seg_id, 'Rmin_last_15000'] = realFFT[-15000:].min()\n",
    "    \n",
    "    # rdg: mean_change_abs corrected\n",
    "    X.loc[seg_id, 'mean_change_abs'] = np.mean(np.abs(np.diff(xc)))\n",
    "    X.loc[seg_id, 'mean_change_rate'] = calc_change_rate(xc)\n",
    "    X.loc[seg_id, 'abs_max'] = np.abs(xc).max()\n",
    "    X.loc[seg_id, 'abs_min'] = np.abs(xc).min()\n",
    "    \n",
    "    # Classical stats by segment\n",
    "    X.loc[seg_id, 'std_first_50000'] = xc[:50000].std()\n",
    "    X.loc[seg_id, 'std_last_50000'] = xc[-50000:].std()\n",
    "    X.loc[seg_id, 'std_first_10000'] = xc[:10000].std()\n",
    "    X.loc[seg_id, 'std_last_10000'] = xc[-10000:].std()\n",
    "    \n",
    "    X.loc[seg_id, 'avg_first_50000'] = xc[:50000].mean()\n",
    "    X.loc[seg_id, 'avg_last_50000'] = xc[-50000:].mean()\n",
    "    X.loc[seg_id, 'avg_first_10000'] = xc[:10000].mean()\n",
    "    X.loc[seg_id, 'avg_last_10000'] = xc[-10000:].mean()\n",
    "    \n",
    "    X.loc[seg_id, 'min_first_50000'] = xc[:50000].min()\n",
    "    X.loc[seg_id, 'min_last_50000'] = xc[-50000:].min()\n",
    "    X.loc[seg_id, 'min_first_10000'] = xc[:10000].min()\n",
    "    X.loc[seg_id, 'min_last_10000'] = xc[-10000:].min()\n",
    "    \n",
    "    X.loc[seg_id, 'max_first_50000'] = xc[:50000].max()\n",
    "    X.loc[seg_id, 'max_last_50000'] = xc[-50000:].max()\n",
    "    X.loc[seg_id, 'max_first_10000'] = xc[:10000].max()\n",
    "    X.loc[seg_id, 'max_last_10000'] = xc[-10000:].max()\n",
    "    \n",
    "    X.loc[seg_id, 'max_to_min'] = xc.max() / np.abs(xc.min())\n",
    "    X.loc[seg_id, 'max_to_min_diff'] = xc.max() - np.abs(xc.min())\n",
    "    X.loc[seg_id, 'count_big'] = len(xc[np.abs(xc) > 500])\n",
    "    X.loc[seg_id, 'sum'] = xc.sum()\n",
    "    \n",
    "    X.loc[seg_id, 'mean_change_rate_first_50000'] = calc_change_rate(xc[:50000])\n",
    "    X.loc[seg_id, 'mean_change_rate_last_50000'] = calc_change_rate(xc[-50000:])\n",
    "    X.loc[seg_id, 'mean_change_rate_first_10000'] = calc_change_rate(xc[:10000])\n",
    "    X.loc[seg_id, 'mean_change_rate_last_10000'] = calc_change_rate(xc[-10000:])\n",
    "    \n",
    "    X.loc[seg_id, 'q95'] = np.quantile(xc, 0.95)\n",
    "    X.loc[seg_id, 'q99'] = np.quantile(xc, 0.99)\n",
    "    X.loc[seg_id, 'q05'] = np.quantile(xc, 0.05)\n",
    "    X.loc[seg_id, 'q01'] = np.quantile(xc, 0.01)\n",
    "    \n",
    "    X.loc[seg_id, 'abs_q95'] = np.quantile(np.abs(xc), 0.95)\n",
    "    X.loc[seg_id, 'abs_q99'] = np.quantile(np.abs(xc), 0.99)\n",
    "    X.loc[seg_id, 'abs_q05'] = np.quantile(np.abs(xc), 0.05)\n",
    "    X.loc[seg_id, 'abs_q01'] = np.quantile(np.abs(xc), 0.01)\n",
    "    \n",
    "    X.loc[seg_id, 'trend'] = add_trend_feature(xc)\n",
    "    X.loc[seg_id, 'abs_trend'] = add_trend_feature(xc, abs_values=True)\n",
    "    X.loc[seg_id, 'abs_mean'] = np.abs(xc).mean()\n",
    "    X.loc[seg_id, 'abs_std'] = np.abs(xc).std()\n",
    "    \n",
    "    X.loc[seg_id, 'mad'] = xc.mad()\n",
    "    X.loc[seg_id, 'kurt'] = xc.kurtosis()\n",
    "    X.loc[seg_id, 'skew'] = xc.skew()\n",
    "    X.loc[seg_id, 'med'] = xc.median()\n",
    "    \n",
    "    X.loc[seg_id, 'Hilbert_mean'] = np.abs(hilbert(xc)).mean()\n",
    "    X.loc[seg_id, 'Hann_window_mean'] = (convolve(xc, hann(150), mode='same') / sum(hann(150))).mean()    \n",
    "    \n",
    "    sta_lta_method = 'Ricard'\n",
    "    classic_sta_lta1 = classic_sta_lta(xc, 500, 10000, method=sta_lta_method)\n",
    "    classic_sta_lta2 = classic_sta_lta(xc, 5000, 100000, method=sta_lta_method)\n",
    "    classic_sta_lta3 = classic_sta_lta(xc, 3333, 6666, method=sta_lta_method)\n",
    "    classic_sta_lta4 = classic_sta_lta(xc, 10000, 25000, method=sta_lta_method)\n",
    "    classic_sta_lta5 = classic_sta_lta(xc, 50, 1000, method=sta_lta_method)\n",
    "    classic_sta_lta6 = classic_sta_lta(xc, 100, 5000, method=sta_lta_method)\n",
    "    classic_sta_lta7 = classic_sta_lta(xc, 333, 666, method=sta_lta_method)\n",
    "    classic_sta_lta8 = classic_sta_lta(xc, 4000, 10000, method=sta_lta_method)\n",
    "    \n",
    "    X.loc[seg_id, 'classic_sta_lta1_mean'] = classic_sta_lta1.mean()\n",
    "    X.loc[seg_id, 'classic_sta_lta2_mean'] = classic_sta_lta2.mean()\n",
    "    X.loc[seg_id, 'classic_sta_lta3_mean'] = classic_sta_lta3.mean()\n",
    "    X.loc[seg_id, 'classic_sta_lta4_mean'] = classic_sta_lta4.mean()\n",
    "    X.loc[seg_id, 'classic_sta_lta5_mean'] = classic_sta_lta5.mean()\n",
    "    X.loc[seg_id, 'classic_sta_lta6_mean'] = classic_sta_lta6.mean()\n",
    "    X.loc[seg_id, 'classic_sta_lta7_mean'] = classic_sta_lta7.mean()\n",
    "    X.loc[seg_id, 'classic_sta_lta8_mean'] = classic_sta_lta8.mean()\n",
    "\n",
    "    X.loc[seg_id, 'classic_sta_lta1_q95'] = np.quantile(classic_sta_lta1, 0.95)\n",
    "    X.loc[seg_id, 'classic_sta_lta2_q95'] = np.quantile(classic_sta_lta2, 0.95)\n",
    "    X.loc[seg_id, 'classic_sta_lta3_q95'] = np.quantile(classic_sta_lta3, 0.95)\n",
    "    X.loc[seg_id, 'classic_sta_lta4_q95'] = np.quantile(classic_sta_lta4, 0.95)\n",
    "    X.loc[seg_id, 'classic_sta_lta5_q95'] = np.quantile(classic_sta_lta5, 0.95)\n",
    "    X.loc[seg_id, 'classic_sta_lta6_q95'] = np.quantile(classic_sta_lta6, 0.95)\n",
    "    X.loc[seg_id, 'classic_sta_lta7_q95'] = np.quantile(classic_sta_lta7, 0.95)\n",
    "    X.loc[seg_id, 'classic_sta_lta8_q95'] = np.quantile(classic_sta_lta8, 0.95)   \n",
    "\n",
    "    X.loc[seg_id, 'classic_sta_lta1_q05'] = np.quantile(classic_sta_lta1, 0.05)\n",
    "    X.loc[seg_id, 'classic_sta_lta2_q05'] = np.quantile(classic_sta_lta2, 0.05)\n",
    "    X.loc[seg_id, 'classic_sta_lta3_q05'] = np.quantile(classic_sta_lta3, 0.05)\n",
    "    X.loc[seg_id, 'classic_sta_lta4_q05'] = np.quantile(classic_sta_lta4, 0.05)\n",
    "    X.loc[seg_id, 'classic_sta_lta5_q05'] = np.quantile(classic_sta_lta5, 0.05)\n",
    "    X.loc[seg_id, 'classic_sta_lta6_q05'] = np.quantile(classic_sta_lta6, 0.05)\n",
    "    X.loc[seg_id, 'classic_sta_lta7_q05'] = np.quantile(classic_sta_lta7, 0.05)\n",
    "    X.loc[seg_id, 'classic_sta_lta8_q05'] = np.quantile(classic_sta_lta8, 0.05)\n",
    "\n",
    "    X.loc[seg_id, 'Moving_average_700_mean'] = xc.rolling(window=700).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'Moving_average_1500_mean'] = xc.rolling(window=1500).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'Moving_average_3000_mean'] = xc.rolling(window=3000).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'Moving_average_6000_mean'] = xc.rolling(window=6000).mean().mean(skipna=True)\n",
    "\n",
    "    ewma = pd.Series.ewm\n",
    "    X.loc[seg_id, 'exp_Moving_average_300_mean'] = (ewma(xc, span=300).mean()).mean(skipna=True)\n",
    "    X.loc[seg_id, 'exp_Moving_average_3000_mean'] = ewma(xc, span=3000).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'exp_Moving_average_6000_mean'] = ewma(xc, span=6000).mean().mean(skipna=True)\n",
    "    X.loc[seg_id, 'exp_Moving_average_30000_mean'] = ewma(xc, span=30000).mean().mean(skipna=True)\n",
    "\n",
    "    # rdg: TODO it seems a parameter to tune\n",
    "    no_of_std = 3\n",
    "    X.loc[seg_id, 'MA_700MA_std_mean'] = xc.rolling(window=700).std().mean()\n",
    "    X.loc[seg_id, 'MA_700MA_BB_high_mean'] = (X.loc[seg_id, 'Moving_average_700_mean']\n",
    "                                              + no_of_std * X.loc[seg_id, 'MA_700MA_std_mean']).mean()\n",
    "    X.loc[seg_id, 'MA_700MA_BB_low_mean'] = (X.loc[seg_id, 'Moving_average_700_mean']\n",
    "                                             - no_of_std * X.loc[seg_id, 'MA_700MA_std_mean']).mean()\n",
    "    X.loc[seg_id, 'MA_400MA_std_mean'] = xc.rolling(window=400).std().mean()\n",
    "    X.loc[seg_id, 'MA_400MA_BB_high_mean'] = (X.loc[seg_id, 'Moving_average_700_mean']\n",
    "                                              + no_of_std * X.loc[seg_id, 'MA_400MA_std_mean']).mean()\n",
    "    X.loc[seg_id, 'MA_400MA_BB_low_mean'] = (X.loc[seg_id, 'Moving_average_700_mean']\n",
    "                                             - no_of_std * X.loc[seg_id, 'MA_400MA_std_mean']).mean()\n",
    "    X.loc[seg_id, 'MA_1000MA_std_mean'] = xc.rolling(window=1000).std().mean()\n",
    "    \n",
    "    X.loc[seg_id, 'iqr'] = np.subtract(*np.percentile(xc, [75, 25]))\n",
    "    X.loc[seg_id, 'q999'] = np.quantile(xc, 0.999)\n",
    "    X.loc[seg_id, 'q001'] = np.quantile(xc, 0.001)\n",
    "    X.loc[seg_id, 'ave10'] = stats.trim_mean(xc, 0.1)\n",
    "\n",
    "    # rdg: The frequency features are new\n",
    "    X.loc[seg_id, 'freq_cross_first_50000'] = freq_from_crossings(xc.values[:50000], fs)\n",
    "    X.loc[seg_id, 'freq_cross_last_50000'] = freq_from_crossings(xc.values[-50000:], fs)\n",
    "    X.loc[seg_id, 'freq_cross_first_10000'] = freq_from_crossings(xc.values[:10000], fs)\n",
    "    X.loc[seg_id, 'freq_cross_last_10000'] = freq_from_crossings(xc.values[-10000:], fs)\n",
    "    \n",
    "    for windows in [10, 100, 1000]:\n",
    "        x_roll_std = xc.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = xc.rolling(windows).mean().dropna().values\n",
    "        \n",
    "        X.loc[seg_id, 'ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "        X.loc[seg_id, 'std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "        X.loc[seg_id, 'max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "        X.loc[seg_id, 'min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "        X.loc[seg_id, 'q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n",
    "        X.loc[seg_id, 'q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n",
    "        X.loc[seg_id, 'q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n",
    "        X.loc[seg_id, 'q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n",
    "        X.loc[seg_id, 'av_change_abs_roll_std_' + str(windows)] = np.mean(np.abs(np.diff(x_roll_std)))\n",
    "        X.loc[seg_id, 'av_change_rate_roll_std_' + str(windows)] = calc_change_rate(pd.Series(x_roll_std))\n",
    "        X.loc[seg_id, 'abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        X.loc[seg_id, 'ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "        X.loc[seg_id, 'std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "        X.loc[seg_id, 'max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "        X.loc[seg_id, 'min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "        X.loc[seg_id, 'q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n",
    "        X.loc[seg_id, 'q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n",
    "        X.loc[seg_id, 'q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n",
    "        X.loc[seg_id, 'q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n",
    "        X.loc[seg_id, 'av_change_abs_roll_mean_' + str(windows)] = np.mean(np.abs(np.diff(x_roll_mean)))\n",
    "        X.loc[seg_id, 'av_change_rate_roll_mean_' + str(windows)] = calc_change_rate(pd.Series(x_roll_mean))\n",
    "        X.loc[seg_id, 'abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the training set\n",
    "Since the testign set is build of sequences of 150.000 samples, let's chop the training set on comparable chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training file with simple derived features\n",
    "segment_size = 150000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_segment_start_ids(sampling_method):\n",
    "    if sampling_method == 'uniform':\n",
    "        # With this approach we obtain 4194 segments\n",
    "        num_segments_training = int(np.floor(train.shape[0] / segment_size))\n",
    "        segment_start_ids = [i * segment_size for i in range(num_segments_training)]\n",
    "    elif sampling_method == 'uniform_no_jump':\n",
    "        # With this approach we obtain 4178 segments (99.5% of 'uniform')\n",
    "        already_sampled = np.full(train.shape[0], False)\n",
    "        num_segments_training = int(np.floor(train.shape[0] / segment_size))\n",
    "        time_to_failure_jumps = np.diff(train['time_to_failure'].values)\n",
    "        num_good_segments_found = 0\n",
    "        segment_start_ids = []\n",
    "        for i in range(num_segments_training):\n",
    "            idx = i * segment_size\n",
    "            # Detect if there is a discontinuity on the time_to_failure signal within the segment\n",
    "            max_jump = np.max(time_to_failure_jumps[idx:idx + segment_size])\n",
    "            if max_jump < 5:\n",
    "                segment_start_ids.append(idx)\n",
    "                num_good_segments_found += 1\n",
    "            else:\n",
    "                print(f'Rejected candidate segment since max_jump={max_jump}')\n",
    "        segment_start_ids.sort()\n",
    "    elif sampling_method == 'random_no_jump':\n",
    "        # With this approach we obtain 4194 segments\n",
    "        num_segments_training = int(np.floor(train.shape[0] / segment_size)) #arbitrary choice\n",
    "        time_to_failure_jumps = np.diff(train['time_to_failure'].values)\n",
    "        num_good_segments_found = 0\n",
    "        segment_start_ids = []\n",
    "        while num_segments_training != num_good_segments_found:\n",
    "            # Generate a random sampling position\n",
    "            idx = random.randint(0, train.shape[0] - segment_size - 1)\n",
    "            # Detect if there is a discontinuity on the time_to_failure signal within the segment\n",
    "            max_jump = np.max(time_to_failure_jumps[idx:idx + segment_size])\n",
    "            if max_jump < 5:\n",
    "                segment_start_ids.append(idx)\n",
    "                num_good_segments_found += 1\n",
    "            else:\n",
    "                print(f'Rejected candidate segment since max_jump={max_jump}')\n",
    "        segment_start_ids.sort()\n",
    "    else:\n",
    "        raise NameError('Method does not exist')\n",
    "    return segment_start_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, we have two strategies implemented.\n",
    "- Uniform sampling: Here the training set is built from consecutive chunks of data. No special care is taken into what's the content of each segment.\n",
    "- Uniform sampling with rejection: Here the training set is built from consecutive chunks of data. There is a control to avoid having in a segment the jump of the `time_to_failure` signal from zero to a high value.\n",
    "- Random sampling with rejection: Here the training set is built from sampling randomly the data. There is a control to avoid having in a segment the jump of the `time_to_failure` signal from zero to a high value. The segments will most likely overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize what happens to the distribution of the `time_to_failure` on teh different samplign strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Generating uniformly sampled training set')\n",
    "segment_start_ids_uniform = generate_segment_start_ids('uniform')\n",
    "\n",
    "print(f'Generating uniformly sampled training set excluding discontinuities in time_to_failure.')\n",
    "segment_start_ids_uniform_no_jump = generate_segment_start_ids('uniform_no_jump')\n",
    "\n",
    "print(f'Generating randomly sampled training set excluding discontinuities in time_to_failure.')\n",
    "print(f'This method may yield overlaping segments')\n",
    "segment_start_ids_random_no_jump = generate_segment_start_ids('random_no_jump')\n",
    "\n",
    "\n",
    "y_tr_samples_uniform = train['time_to_failure'].values[np.array(\n",
    "    segment_start_ids_uniform) + segment_size - 1]\n",
    "y_tr_samples_uniform_no_jump = train['time_to_failure'].values[\n",
    "    np.array(segment_start_ids_uniform_no_jump) + segment_size - 1]\n",
    "y_tr_samples_random_no_jump = train['time_to_failure'].values[\n",
    "    np.array(segment_start_ids_random_no_jump) + segment_size - 1]\n",
    "\n",
    "plt.subplots(figsize=(16, 16))\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.plot(segment_start_ids_uniform)\n",
    "plt.title('segment_start_ids_uniform')\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.plot(segment_start_ids_uniform_no_jump)\n",
    "plt.title('segment_start_ids_uniform_no_jump')\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.plot(segment_start_ids_random_no_jump)\n",
    "plt.title('segment_start_ids_random_no_jump')\n",
    "\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.plot(y_tr_samples_uniform)\n",
    "plt.title('time_to_failure values (all)')\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.plot(y_tr_samples_uniform_no_jump)\n",
    "plt.title('time_to_failure values (uniform sampling no jump)')\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.plot(y_tr_samples_random_no_jump)\n",
    "plt.title('time_to_failure values (random sampling no jump)')\n",
    "\n",
    "plt.subplot(3, 3, 7)\n",
    "plt.hist(y_tr_samples_uniform, bins='auto', alpha=0.5, density=True)\n",
    "plt.hist(train['time_to_failure'].values[::50], bins='auto', alpha=0.5, density=True)\n",
    "plt.title('With discontinuities (contiguous)')\n",
    "plt.legend(['Sampled', 'All data'])\n",
    "\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.hist(y_tr_samples_uniform_no_jump, bins='auto', alpha=0.5, density=True)\n",
    "plt.hist(train['time_to_failure'].values[::50], bins='auto', alpha=0.5, density=True)\n",
    "plt.title('Discarding discontinuities (contiguous)')\n",
    "plt.legend(['Sampled', 'All data'])\n",
    "\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.hist(y_tr_samples_random_no_jump, bins='auto', alpha=0.5, density=True)\n",
    "plt.title('Discarding discontinuities (rand)')\n",
    "plt.hist(train['time_to_failure'].values[::50], bins='auto', alpha=0.5, density=True)\n",
    "plt.legend(['Sampled', 'All data'])\n",
    "plt.show()\n",
    "\n",
    "del segment_start_ids_uniform\n",
    "del segment_start_ids_uniform_no_jump\n",
    "del segment_start_ids_random_no_jump\n",
    "del y_tr_samples_uniform\n",
    "del y_tr_samples_uniform_no_jump\n",
    "del y_tr_samples_random_no_jump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we choose one sampling method (`uniform`) and run with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_start_ids = generate_segment_start_ids('uniform_no_jump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.DataFrame(index=range(len(segment_start_ids)), dtype=np.float64)\n",
    "y_tr = pd.DataFrame(index=range(len(segment_start_ids)), dtype=np.float64, columns=['time_to_failure'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute all features for all segments (WARNING: it takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm_notebook(range(len(segment_start_ids))):        \n",
    "    seg_id = segment_start_ids[idx]\n",
    "    seg = train.iloc[seg_id:seg_id + segment_size]\n",
    "    create_features(idx, seg, X_tr)\n",
    "    y_tr.loc[idx, 'time_to_failure'] = seg['time_to_failure'].values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{X_tr.shape[0]} samples in new train data and {X_tr.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look of how some of these features look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(44, 24))\n",
    "cols = list(np.abs(X_tr.corrwith(y_tr['time_to_failure'])).sort_values(ascending=False).head(24).index)\n",
    "for i, col in enumerate(cols):\n",
    "    ax1 = plt.subplot(6, 4, i + 1)\n",
    "    plt.plot(X_tr[col], color='blue')\n",
    "    plt.title(col)\n",
    "    ax1.set_ylabel(col, color='b')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    plt.plot(y_tr, color='g')\n",
    "    ax2.set_ylabel('time_to_failure', color='g')\n",
    "    plt.legend([col, 'time_to_failure'])\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, there are features that exploded, which show as `np.inf` in the array. Let's just replace them by the mean values. TODO: check if this is the appropiate strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "for col in X_tr.columns:\n",
    "    if X_tr[col].isnull().any():\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_tr), columns=X_tr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')\n",
    "X_test = pd.DataFrame(columns=X_tr.columns, dtype=np.float64, index=submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 16))\n",
    "for i, seg_id in enumerate(tqdm_notebook(X_test.index)):\n",
    "    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "    create_features(seg_id, seg, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].isnull().any():\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(estimator, grid, features, target, num_folds):\n",
    "    \"\"\"Return the best hyperparameters combination in grid.\"\"\"\n",
    "    t0 = time.time()\n",
    "    reg = GridSearchCV(estimator, grid, cv=num_folds, scoring='neg_mean_absolute_error', n_jobs=-1, verbose=10)\n",
    "    reg.fit(features, target)\n",
    "    \n",
    "    t0 = time.time() - t0\n",
    "    print(\"Best CV score: {:.4f}, time: {:.1f}s\".format(-reg.best_score_, t0))\n",
    "    print(reg.best_params_)\n",
    "    return reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, folds, params=None, model_type='lgb',\n",
    "                model=None, show_scatter=False):\n",
    "\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    n_fold = folds.get_n_splits()\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = 50000, n_jobs = 32)\n",
    "            model.fit(X_train, y_train, \n",
    "                      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                      eval_metric='mae',\n",
    "                      verbose=10000,\n",
    "                      early_stopping_rounds=2000)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data,\n",
    "                              num_boost_round=20000,\n",
    "                              evals=watchlist,\n",
    "                              early_stopping_rounds=200,\n",
    "                              verbose_eval=500,\n",
    "                              params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns),\n",
    "                                         ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = mean_absolute_error(y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. MAE: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric='MAE', task_type='GPU', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True,\n",
    "                      verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        if model_type == 'gdi':\n",
    "            y_pred_valid = gpi(X_valid).values\n",
    "            y_pred = gpi(X_test).values\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(mean_absolute_error(y_valid, y_pred_valid))\n",
    "        \n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance['feature'] = X.columns\n",
    "            fold_importance['importance'] = model.feature_importances_\n",
    "            fold_importance['fold'] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    if show_scatter:\n",
    "        fig, axis = plt.subplots(1, 2, figsize=(12,5))\n",
    "        ax1, ax2 = axis\n",
    "        ax1.set_xlabel('actual')\n",
    "        ax1.set_ylabel('predicted')\n",
    "        ax2.set_xlabel('train index')\n",
    "        ax2.set_ylabel('time to failure')\n",
    "        \n",
    "        ax1.scatter(y, oof, color='brown')\n",
    "        ax1.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)], color='blue')\n",
    "\n",
    "        ax2.plot(y, color='blue', label='y_train')\n",
    "        ax2.plot(oof, color='orange')\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance['importance'] /= n_fold\n",
    "        return oof, prediction, np.mean(scores), np.std(scores), feature_importance\n",
    "    else:\n",
    "        return oof, prediction, np.mean(scores), np.std(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold_features = 5\n",
    "folds_features = KFold(n_splits=n_fold_features, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 54,\n",
    "    'min_data_in_leaf': 79,\n",
    "    'objective': 'huber',\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting': 'gbdt',\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.8126672064208567,\n",
    "    'bagging_seed': 11,\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'reg_alpha': 0.1302650970728192,\n",
    "    'reg_lambda': 0.3603427518866501\n",
    "}\n",
    "oof_lgb, prediction_lgb, score_mean_lgb, score_std_lgb, feature_importance_lgb = train_model(\n",
    "    X=X_train_scaled,\n",
    "    X_test=X_test_scaled,\n",
    "    y=y_tr,\n",
    "    folds=folds_features,\n",
    "    params=params,\n",
    "    model_type='lgb',\n",
    "    show_scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building a simple mode, let's see which are the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_features = 179\n",
    "cols_feat = (feature_importance_lgb[['feature', 'importance']]\n",
    "        .groupby('feature')\n",
    "        .mean()\n",
    "        .sort_values(by='importance', ascending=False)[:max_num_features].index)\n",
    "best_features = feature_importance_lgb.loc[feature_importance_lgb.feature.isin(cols_feat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,26))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_lgb.sort_values(by='importance', ascending=False))\n",
    "plt.title('LightGBM Features (averaged over folds)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Clearly, come features do not seem to bring any value to the mix. Let's visualize it carefully in case there is something wrong with them (or even if they make sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_list = cols_feat.tolist()\n",
    "X_train_scaled_best = X_train_scaled[best_features_list]\n",
    "X_test_scaled_best = X_test_scaled[best_features_list]\n",
    "n_fold_models = 5\n",
    "folds_models = KFold(n_splits=n_fold_models, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "Let's try a few different models and submit the one with the best validation score. The predicted values in the following plots are using a out-of-fold scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "Gradient boosting that uses tree based learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first search for the best parameters for this model. It is not possible to use `GridSearchCV` with early stopping (lightgbm), so I am using a custom function for random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    'objective': 'huber',\n",
    "    'boosting': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'random_seed': 19,\n",
    "    'n_estimators': 50000,\n",
    "    'metric': 'mae',\n",
    "    'bagging_seed': 11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': list(range(8, 92, 4)),\n",
    "    'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [3, 4, 5, 6, 8, 12, 16, -1],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005],\n",
    "    'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 1\n",
    "for param in param_grid:\n",
    "    grid_size *= len(param_grid[param])\n",
    "print(f'The search grid has {grid_size} elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 999\n",
    "dataset = lgb.Dataset(X_train_scaled_best, label=y_tr)  # no need to scale features\n",
    "\n",
    "for i in range(200):\n",
    "    params = {k: random.choice(v) for k, v in param_grid.items()}\n",
    "    params.update(fixed_params)\n",
    "    result = lgb.cv(params, dataset,\n",
    "                    nfold=n_fold_models,\n",
    "                    early_stopping_rounds=200,\n",
    "                    stratified=False)\n",
    "    \n",
    "    print(f\"Iteration {i} finished with mae={result['l1-mean'][-1]}\")\n",
    "    \n",
    "    if result['l1-mean'][-1] < best_score:\n",
    "        best_score = result['l1-mean'][-1]\n",
    "        best_params = params\n",
    "        best_nrounds = len(result['l1-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'huber',\n",
    "    'boosting': 'gbdt',\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 8, #54,\n",
    "    'min_data_in_leaf': 60, #79,\n",
    "    'max_depth': 3, #-1,\n",
    "    'learning_rate': 0.01, #0.01,\n",
    "    'bagging_freq': 4, #5,\n",
    "    'bagging_fraction': 0.9111111111111111, #0.8126672064208567,\n",
    "    'bagging_seed': 11,\n",
    "    'metric': 'mae',\n",
    "    'reg_alpha': 0.5722222222222222, #0.1302650970728192,\n",
    "    'reg_lambda': 0.95 #0.3603427518866501\n",
    "}\n",
    "oof_lgb, prediction_lgb, score_mean_lgb, score_std_lgb, feature_importance = train_model(X=X_train_scaled_best,\n",
    "                                                                                         X_test=X_test_scaled_best,\n",
    "                                                                                         y=y_tr,\n",
    "                                                                                         folds=folds_models,\n",
    "                                                                                         params=params,\n",
    "                                                                                         model_type='lgb',\n",
    "                                                                                         show_scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting (a different one)\n",
    "Gradient boosting that uses tree based learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first search for the best parameters for this model. It is not possible to use `GridSearchCV` with early stopping (lightgbm), so I am using a custom function for random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.03, #Andrew uses 0.03\n",
    "    'max_depth': 10,\n",
    "    'subsample': 0.9,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'silent': True,\n",
    "    'nthread': 32\n",
    "}\n",
    "oof_xgb, prediction_xgb, score_mean_xgb, score_std_xgb = train_model(X=X_train_scaled_best,\n",
    "                                                                     X_test=X_test_scaled_best,\n",
    "                                                                     y=y_tr,\n",
    "                                                                     folds=folds_models,\n",
    "                                                                     params=xgb_params,\n",
    "                                                                     model_type='xgb',\n",
    "                                                                     show_scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu Support Vector Regression\n",
    "Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first search for the best parameters ($\\nu$ and $C$) for this model using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [{'nu': np.linspace(0.5, 0.95, 15),\n",
    "         'C': np.linspace(5, 15, 15)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target = y_tr.values.flatten()\n",
    "params = grid_search_cv(NuSVR(gamma='scale', tol=0.01), grid, X_train_scaled_best, target, n_fold_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can put the best parameters in builidng the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = NuSVR(gamma='scale', nu=0.9, C=10.0, tol=0.01)\n",
    "model = NuSVR(gamma='scale', nu=0.5642857142857143, C=5, tol=0.01)\n",
    "oof_svr, prediction_svr, score_mean_svr, score_std_svr = train_model(X=X_train_scaled_best,\n",
    "                                                                     X_test=X_test_scaled_best,\n",
    "                                                                     y=y_tr,\n",
    "                                                                     folds=folds_models,\n",
    "                                                                     params=None,\n",
    "                                                                     model_type='sklearn',\n",
    "                                                                     model=model,\n",
    "                                                                     show_scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu Support Vector Regression (another one)\n",
    "Similar to NuSVC, for regression, uses a parameter nu to control the number of support vectors. However, unlike NuSVC, where nu replaces C, here nu replaces the parameter epsilon of epsilon-SVR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first search for the best parameters ($\\nu$ and $C$) for this model using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [{'nu': np.linspace(0.3, 0.8, 15),\n",
    "         'C': np.linspace(0.5, 2, 15)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target = y_tr.values.flatten()\n",
    "params = grid_search_cv(NuSVR(gamma='scale', tol=0.01), grid, X_train_scaled_best, target, n_fold_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can put the best parameters in builidng the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model = NuSVR(gamma='scale', nu=0.7, C=1.0, tol=0.01)\n",
    "model = NuSVR(gamma='scale', nu=0.6214285714285714, C=0.5, tol=0.01)\n",
    "oof_svr1, prediction_svr1, score_mean_svr1, score_std_svr1 = train_model(X=X_train_scaled_best,\n",
    "                                                                         X_test=X_test_scaled_best,\n",
    "                                                                         y=y_tr,\n",
    "                                                                         folds=folds_models,\n",
    "                                                                         params=None,\n",
    "                                                                         model_type='sklearn',\n",
    "                                                                         model=model,\n",
    "                                                                         show_scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'loss_function':'MAE'}\n",
    "oof_cat, prediction_cat, score_mean_cat, score_std_cat = train_model(X=X_train_scaled_best,\n",
    "                                                                     X_test=X_test_scaled_best,\n",
    "                                                                     y=y_tr,\n",
    "                                                                     folds=folds_models,\n",
    "                                                                     params=params,\n",
    "                                                                     model_type='cat',\n",
    "                                                                     show_scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge\n",
    "This model combines regularized linear regression with a given kernel (radial basis in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first search for the best parameters ($\\alpha$ and $\\gamma$) for this model using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [{'alpha': np.linspace(0.0005, 0.1, 15),\n",
    "         'gamma': np.linspace(0.01, 0.1, 15)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target = y_tr.values.flatten()\n",
    "params = grid_search_cv(KernelRidge(kernel='rbf'), grid, X_train_scaled_best, target, n_fold_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can put the best parameters in builidng the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KernelRidge(kernel='rbf', alpha=0.1, gamma=0.01) #Original parameters\n",
    "model = KernelRidge(kernel='rbf', alpha=0.0005, gamma=0.043750000000000004)\n",
    "oof_r, prediction_r, score_mean_r, score_std_r = train_model(X=X_train_scaled_best,\n",
    "                                                             X_test=X_test_scaled_best,\n",
    "                                                             y=y_tr,\n",
    "                                                             folds=folds_models,\n",
    "                                                             params=None,\n",
    "                                                             model_type='sklearn',\n",
    "                                                             model=model,\n",
    "                                                             show_scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Program Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_gdi, prediction_gdi, score_mean_gdi, score_std_gdi = train_model(X=X_train_scaled_best,\n",
    "                                                                     X_test=X_test_scaled_best,\n",
    "                                                                     y=y_tr,\n",
    "                                                                     folds=folds_models,\n",
    "                                                                     model_type='gdi',\n",
    "                                                                     show_scatter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only real difference is scaling the lot in one go rather than scling train and then using this to scale test\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and blending\n",
    "And now let's try stacking :) We can use the same function for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = np.vstack([oof_lgb, oof_xgb, oof_svr, oof_svr1, oof_r, oof_cat, oof_gdi]).transpose()\n",
    "train_stack = pd.DataFrame(train_stack, columns = ['lgb', 'xgb', 'svr', 'svr1', 'r', 'cat', 'gdi'])\n",
    "test_stack = np.vstack([prediction_lgb, prediction_xgb, prediction_svr, prediction_svr1, prediction_r,\n",
    "                        prediction_cat, prediction_gdi]).transpose()\n",
    "test_stack = pd.DataFrame(test_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_lgb_stack, prediction_lgb_stack, score_mean_stack, score_std_stack, feature_importance = train_model(\n",
    "    X=train_stack,\n",
    "    X_test=test_stack,\n",
    "    y=y_tr,\n",
    "    folds=folds_models,\n",
    "    params=params,\n",
    "    model_type='lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = feature_importance[['feature', 'importance']].groupby('feature').mean().sort_values(\n",
    "    by='importance', ascending=False).index\n",
    "best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "plt.figure(figsize=(16, 8));\n",
    "sns.barplot(x='importance', y='feature', data=best_features.sort_values(by='importance', ascending=False));\n",
    "plt.title('LGB Features (avg over folds)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot(oof_lgb, color='b', label='lgb')\n",
    "plt.legend()\n",
    "plt.title('lgb');\n",
    "\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot(oof_xgb, color='teal', label='xgb')\n",
    "plt.legend()\n",
    "plt.title('xgb');\n",
    "\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot(oof_svr, color='red', label='svr')\n",
    "plt.legend()\n",
    "plt.title('svr');\n",
    "\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot(oof_svr1, color='red', label='svr1')\n",
    "plt.legend()\n",
    "plt.title('svr1');\n",
    "\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot(oof_r, color='b', label='r')\n",
    "plt.legend()\n",
    "plt.title('r');\n",
    "\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot(oof_cat, color='b', label='cat')\n",
    "plt.legend()\n",
    "plt.title('cat');\n",
    "\n",
    "plt.subplot(3, 3, 7)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot(oof_gdi, color='b', label='gdi')\n",
    "plt.legend()\n",
    "plt.title('gdi');\n",
    "\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot(oof_lgb_stack, color='gold', label='stack')\n",
    "plt.legend()\n",
    "plt.title('stacked');\n",
    "\n",
    "plt.subplot(3, 3, 9)\n",
    "plt.plot(y_tr, color='g', label='y_train')\n",
    "plt.plot((oof_lgb + oof_xgb + oof_svr + oof_svr1 + oof_r + oof_cat + oof_gdi) / 7, color='gold', label='blend')\n",
    "plt.legend()\n",
    "plt.title('blend');\n",
    "plt.suptitle('Predictions vs actual');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - Blend model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = (prediction_lgb + prediction_xgb + prediction_svr +\n",
    "                                 prediction_svr1 + prediction_cat + prediction_r + prediction_gdi ) / 7\n",
    "submission.to_csv('../output/submission_rdg_notebook3_blend.csv')\n",
    "score_mean_blend = (score_mean_lgb + score_mean_xgb + score_mean_svr + score_mean_svr1 + score_mean_cat\n",
    "                    + score_mean_r + score_mean_gdi) / 7\n",
    "score_std_blend = (score_std_lgb + score_std_xgb + score_std_svr + score_std_svr1 + score_std_cat\n",
    "                    + score_std_r + score_std_gdi) / 7\n",
    "print(f'CV mean score: {score_mean_blend:.4f}, std: {score_std_blend:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - Stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = prediction_lgb_stack\n",
    "submission.to_csv('../output/submission_rdg_notebook3_stack.csv')\n",
    "print(f'CV mean score: {score_mean_stack:.4f}, std: {score_std_stack:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - LGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = prediction_lgb\n",
    "submission.to_csv('../output/submission_rdg_notebook3_lgb.csv')\n",
    "print(f'CV mean score: {score_mean_lgb:.4f}, std: {score_std_lgb:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = prediction_xgb\n",
    "submission.to_csv('../output/submission_rdg_notebook3_xgb.csv')\n",
    "print(f'CV mean score: {score_mean_xgb:.4f}, std: {score_std_xgb:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - SVR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = prediction_svr\n",
    "submission.to_csv('../output/submission_rdg_notebook3_svr.csv')\n",
    "print(f'CV mean score: {score_mean_svr:.4f}, std: {score_std_svr:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - SVR1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = prediction_svr1\n",
    "submission.to_csv('../output/submission_rdg_notebook3_svr1.csv')\n",
    "print(f'CV mean score: {score_mean_svr1:.4f}, std: {score_std_svr1:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - CAT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = prediction_svr1\n",
    "submission.to_csv('../output/submission_rdg_notebook3_cat.csv')\n",
    "print(f'CV mean score: {score_mean_cat:.4f}, std: {score_std_cat:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - R model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = prediction_r\n",
    "submission.to_csv('../output/submission_rdg_notebook3_r.csv')\n",
    "print(f'CV mean score: {score_mean_r:.4f}, std: {score_std_r:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission - GDI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = prediction_gdi\n",
    "submission.to_csv('../output/submission_rdg_notebook3_gdi.csv')\n",
    "print(f'CV mean score: {score_mean_gdi:.4f}, std: {score_std_gdi:.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.loc['lgb', 'mean'] = score_mean_lgb\n",
    "evaluation.loc['lgb', 'std'] = score_std_lgb\n",
    "\n",
    "evaluation.loc['xgb', 'mean'] = score_mean_xgb\n",
    "evaluation.loc['xgb', 'std'] = score_std_xgb\n",
    "\n",
    "evaluation.loc['svr', 'mean'] = score_mean_svr\n",
    "evaluation.loc['svr', 'std'] = score_std_svr\n",
    "\n",
    "evaluation.loc['svr1', 'mean'] = score_mean_svr1\n",
    "evaluation.loc['svr1', 'std'] = score_std_svr1\n",
    "\n",
    "evaluation.loc['cat', 'mean'] = score_mean_cat\n",
    "evaluation.loc['cat', 'std'] = score_std_cat\n",
    "\n",
    "evaluation.loc['r', 'mean'] = score_mean_r\n",
    "evaluation.loc['r', 'std'] = score_std_r\n",
    "\n",
    "evaluation.loc['gdi', 'mean'] = score_mean_gdi\n",
    "evaluation.loc['gdi', 'std'] = score_std_gdi\n",
    "\n",
    "evaluation.loc['blend', 'mean'] = score_mean_blend\n",
    "evaluation.loc['blend', 'std'] = score_std_blend\n",
    "\n",
    "evaluation.loc['stack', 'mean'] = score_mean_stack\n",
    "evaluation.loc['stack', 'std'] = score_std_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 5))\n",
    "ax.bar(np.arange(len(evaluation.index.tolist())), evaluation['mean'], yerr=evaluation['std'], align='center',\n",
    "       alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylabel('CV score')\n",
    "ax.set_xticks(np.arange(len(evaluation.index.tolist())))\n",
    "ax.set_xticklabels(evaluation.index.tolist())\n",
    "ax.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
